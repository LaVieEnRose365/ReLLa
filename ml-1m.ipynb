{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import copy\n",
    "from transformers import set_seed\n",
    "import hashlib\n",
    "import json\n",
    "import pickle as pkl\n",
    "import h5py\n",
    "import collections\n",
    "from tqdm import tqdm\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "dataset_name = \"ml-1m\"\n",
    "root = f\"../data/{dataset_name}\"\n",
    "source_dir = os.path.join(root, \"raw_data\")\n",
    "target_dir = os.path.join(root, \"proc_data\")\n",
    "\n",
    "os.makedirs(target_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_dict = {\n",
    "    1: \"under 18\",\n",
    "    18: \"18-24\",\n",
    "    25: \"25-34\",\n",
    "    35: \"35-44\",\n",
    "    45: \"45-49\",\n",
    "    50: \"50-55\",\n",
    "    56: \"above 56\"\n",
    "}\n",
    "\n",
    "job_dict = {\n",
    "    0: \"other or not specified\",\n",
    "\t1: \"academic/educator\",\n",
    "\t2: \"artist\",\n",
    "\t3: \"clerical/admin\",\n",
    "\t4: \"college/grad student\",\n",
    "\t5: \"customer service\",\n",
    "\t6: \"doctor/health care\",\n",
    "\t7: \"executive/managerial\",\n",
    "\t8: \"farmer\",\n",
    "\t9: \"homemaker\",\n",
    "\t10: \"K-12 student\",\n",
    "\t11: \"lawyer\",\n",
    "\t12: \"programmer\",\n",
    "\t13: \"retired\",\n",
    "\t14: \"sales/marketing\",\n",
    "\t15: \"scientist\",\n",
    "\t16: \"self-employed\",\n",
    "\t17: \"technician/engineer\",\n",
    "\t18: \"tradesman/craftsman\",\n",
    "\t19: \"unemployed\",\n",
    "\t20: \"writer\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of users: 6040\n"
     ]
    }
   ],
   "source": [
    "# User data\n",
    "\n",
    "user_data = []\n",
    "user_fields = [\"User ID\", \"Gender\", \"Age\", \"Job\", \"Zipcode\"]\n",
    "for line in open(os.path.join(source_dir, \"users.dat\"), \"r\").readlines():\n",
    "    ele = line.strip().split(\"::\")\n",
    "    user_id, gender, age, job, zipcode = [x.strip() for x in ele]\n",
    "    gender = \"male\" if gender == \"M\" else \"female\"\n",
    "    age = age_dict[int(age)]\n",
    "    job = job_dict[int(job)]\n",
    "    user_data.append([int(user_id), gender, age, job, zipcode])\n",
    "\n",
    "df_user = pd.DataFrame(user_data, columns=user_fields)\n",
    "print(f\"Total number of users: {len(df_user)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of movies: 3883\n"
     ]
    }
   ],
   "source": [
    "# Movie data\n",
    "\n",
    "movie_data = []\n",
    "movie_detail = {}\n",
    "movie_fields = [\"Movie ID\", \"Movie title\", \"Movie genre\"]\n",
    "for line in open(os.path.join(source_dir, \"movies.dat\"), \"r\", encoding=\"ISO-8859-1\").readlines():\n",
    "    ele = line.strip().split(\"::\")\n",
    "    movie_id = int(ele[0].strip())\n",
    "    movie_title = ele[1].strip()\n",
    "    movie_genre = ele[2].strip().split(\"|\")[0]\n",
    "    movie_data.append([movie_id, movie_title, movie_genre])\n",
    "    movie_detail[movie_id] = [movie_title, movie_genre]\n",
    "\n",
    "df_movie = pd.DataFrame(movie_data, columns=movie_fields)\n",
    "print(f\"Total number of movies: {len(df_movie)}\")\n",
    "\n",
    "json.dump(movie_detail, open(os.path.join(target_dir, \"movie_detail.json\"), \"w\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of ratings: 1000209\n"
     ]
    }
   ],
   "source": [
    "# Rating data\n",
    "\n",
    "rating_data = []\n",
    "rating_fields = [\"User ID\", \"Movie ID\", \"rating\", \"timestamp\", \"labels\"]\n",
    "user_list, movie_list = list(df_user[\"User ID\"]), list(df_movie[\"Movie ID\"])\n",
    "for line in open(os.path.join(source_dir, \"ratings.dat\"), \"r\").readlines():\n",
    "    ele = [x.strip() for x in line.strip().split(\"::\")] \n",
    "    user, movie, rating, timestamp = int(ele[0]), int(ele[1]), int(ele[2]), int(ele[3])\n",
    "    label = 1 if rating > 3 else 0\n",
    "    if user in user_list and movie in movie_list:\n",
    "        rating_data.append([user, movie, rating, timestamp, label])\n",
    "\n",
    "df_ratings = pd.DataFrame(rating_data, columns=rating_fields)\n",
    "print(f\"Total number of ratings: {len(df_ratings)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Job</th>\n",
       "      <th>Zipcode</th>\n",
       "      <th>Movie ID</th>\n",
       "      <th>Movie title</th>\n",
       "      <th>Movie genre</th>\n",
       "      <th>rating</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>956703932</td>\n",
       "      <td>6040</td>\n",
       "      <td>male</td>\n",
       "      <td>25-34</td>\n",
       "      <td>doctor/health care</td>\n",
       "      <td>11106</td>\n",
       "      <td>858</td>\n",
       "      <td>Godfather, The (1972)</td>\n",
       "      <td>Action</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>956703954</td>\n",
       "      <td>6040</td>\n",
       "      <td>male</td>\n",
       "      <td>25-34</td>\n",
       "      <td>doctor/health care</td>\n",
       "      <td>11106</td>\n",
       "      <td>593</td>\n",
       "      <td>Silence of the Lambs, The (1991)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>956703954</td>\n",
       "      <td>6040</td>\n",
       "      <td>male</td>\n",
       "      <td>25-34</td>\n",
       "      <td>doctor/health care</td>\n",
       "      <td>11106</td>\n",
       "      <td>2384</td>\n",
       "      <td>Babe: Pig in the City (1998)</td>\n",
       "      <td>Children's</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>956703977</td>\n",
       "      <td>6040</td>\n",
       "      <td>male</td>\n",
       "      <td>25-34</td>\n",
       "      <td>doctor/health care</td>\n",
       "      <td>11106</td>\n",
       "      <td>1961</td>\n",
       "      <td>Rain Man (1988)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>956703977</td>\n",
       "      <td>6040</td>\n",
       "      <td>male</td>\n",
       "      <td>25-34</td>\n",
       "      <td>doctor/health care</td>\n",
       "      <td>11106</td>\n",
       "      <td>2019</td>\n",
       "      <td>Seven Samurai (The Magnificent Seven) (Shichin...</td>\n",
       "      <td>Action</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  User ID Gender    Age                 Job Zipcode  Movie ID  \\\n",
       "0  956703932     6040   male  25-34  doctor/health care   11106       858   \n",
       "1  956703954     6040   male  25-34  doctor/health care   11106       593   \n",
       "2  956703954     6040   male  25-34  doctor/health care   11106      2384   \n",
       "3  956703977     6040   male  25-34  doctor/health care   11106      1961   \n",
       "4  956703977     6040   male  25-34  doctor/health care   11106      2019   \n",
       "\n",
       "                                         Movie title Movie genre  rating  \\\n",
       "0                              Godfather, The (1972)      Action       4   \n",
       "1                   Silence of the Lambs, The (1991)       Drama       5   \n",
       "2                       Babe: Pig in the City (1998)  Children's       4   \n",
       "3                                    Rain Man (1988)       Drama       4   \n",
       "4  Seven Samurai (The Magnificent Seven) (Shichin...      Action       5   \n",
       "\n",
       "   labels  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge df_user/df_movie/df_rating into df_data\n",
    "\n",
    "df_data = pd.merge(df_ratings, df_user, on=[\"User ID\"], how=\"inner\")\n",
    "df_data = pd.merge(df_data, df_movie, on=[\"Movie ID\"], how=\"inner\")\n",
    "\n",
    "df_data.sort_values(by=[\"timestamp\", \"User ID\", \"Movie ID\"], inplace=True, kind=\"stable\")\n",
    "\n",
    "field_names = [\"timestamp\", \"User ID\", \"Gender\", \"Age\", \"Job\", \"Zipcode\", \"Movie ID\", \"Movie title\", \"Movie genre\", \"rating\", \"labels\"]\n",
    "\n",
    "df_data = df_data[field_names].reset_index(drop=True)\n",
    "\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000209it [02:03, 8112.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID 6040\n",
      "Gender 2\n",
      "Age 7\n",
      "Job 21\n",
      "Zipcode 3439\n",
      "Movie ID 3706\n",
      "Movie title 3706\n",
      "Movie genre 18\n",
      "---------------------------------------------------------------\n",
      "User ID 6040 0\n",
      "Gender 2 6040\n",
      "Age 7 6042\n",
      "Job 21 6049\n",
      "Zipcode 3439 6070\n",
      "Movie ID 3706 9509\n",
      "Movie title 3706 13215\n",
      "Movie genre 18 16921\n",
      "---------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Encode the feature dict for CTR data\n",
    "\n",
    "def add_to_dict(dict, feature):\n",
    "    if feature not in dict:\n",
    "        dict[feature] = len(dict)\n",
    "\n",
    "field_names = [\"User ID\", \"Gender\", \"Age\", \"Job\", \"Zipcode\", \"Movie ID\", \"Movie title\", \"Movie genre\"]\n",
    "feature_dict = {field : {} for field in field_names}\n",
    "\n",
    "\n",
    "for idx, row in tqdm(df_data.iterrows()):\n",
    "    for field in field_names:\n",
    "        add_to_dict(feature_dict[field], row[field])\n",
    "\n",
    "feature_count = [len(feature_dict[field]) for field in field_names]\n",
    "\n",
    "feature_offset = [0]\n",
    "for c in feature_count[:-1]:\n",
    "    feature_offset.append(feature_offset[-1] + c)\n",
    "\n",
    "for field in field_names:\n",
    "    print(field, len(feature_dict[field]))\n",
    "\n",
    "print(\"---------------------------------------------------------------\")\n",
    "for f, fc, fo in zip(field_names, feature_count, feature_offset):\n",
    "    print(f, fc, fo)\n",
    "print(\"---------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000209it [02:01, 8232.63it/s]\n"
     ]
    }
   ],
   "source": [
    "# Collect user history (<= 30)\n",
    "\n",
    "user_history_dict = {\n",
    "    \"ID\": {k: [] for k in set(df_data[\"User ID\"])},\n",
    "    \"rating\": {k: [] for k in set(df_data[\"User ID\"])},\n",
    "}\n",
    "history_column = {\n",
    "    \"ID\": [],\n",
    "    \"rating\": [],\n",
    "}\n",
    "movie_id_to_title = {}\n",
    "\n",
    "for idx, row in tqdm(df_data.iterrows()):\n",
    "    user_id, movie_id, rating, title = row[\"User ID\"], row[\"Movie ID\"], row[\"rating\"], row[\"Movie title\"]\n",
    "    history_column[\"ID\"].append(user_history_dict[\"ID\"][user_id].copy())\n",
    "    history_column[\"rating\"].append(user_history_dict[\"rating\"][user_id].copy())\n",
    "    user_history_dict[\"ID\"][user_id].append(movie_id)\n",
    "    user_history_dict[\"rating\"][user_id].append(rating)\n",
    "    if movie_id not in movie_id_to_title:\n",
    "        movie_id_to_title[movie_id] = title\n",
    "\n",
    "json.dump(movie_id_to_title, open(os.path.join(target_dir, \"id_to_title.json\"), \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "970009it [01:36, 10026.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   timestamp  User ID Gender    Age                 Job Zipcode  Movie ID  \\\n",
      "0  956704056     6040   male  25-34  doctor/health care   11106       213   \n",
      "1  956704056     6040   male  25-34  doctor/health care   11106       573   \n",
      "2  956704056     6040   male  25-34  doctor/health care   11106      1419   \n",
      "3  956704056     6040   male  25-34  doctor/health care   11106      3111   \n",
      "4  956704056     6040   male  25-34  doctor/health care   11106      3505   \n",
      "\n",
      "                                         Movie title Movie genre  rating  \\\n",
      "0     Burnt By the Sun (Utomlyonnye solntsem) (1994)       Drama       5   \n",
      "1  Ciao, Professore! (Io speriamo che me la cavo ...       Drama       4   \n",
      "2                                   Walkabout (1971)       Drama       3   \n",
      "3                         Places in the Heart (1984)       Drama       5   \n",
      "4                                  No Way Out (1987)    Thriller       4   \n",
      "\n",
      "   labels                                         history ID  \\\n",
      "0       1                       [858, 593, 2384, 1961, 2019]   \n",
      "1       1                  [858, 593, 2384, 1961, 2019, 213]   \n",
      "2       0             [858, 593, 2384, 1961, 2019, 213, 573]   \n",
      "3       1       [858, 593, 2384, 1961, 2019, 213, 573, 1419]   \n",
      "4       1  [858, 593, 2384, 1961, 2019, 213, 573, 1419, 3...   \n",
      "\n",
      "                history rating  \n",
      "0              [4, 5, 4, 4, 5]  \n",
      "1           [4, 5, 4, 4, 5, 5]  \n",
      "2        [4, 5, 4, 4, 5, 5, 4]  \n",
      "3     [4, 5, 4, 4, 5, 5, 4, 3]  \n",
      "4  [4, 5, 4, 4, 5, 5, 4, 3, 5]  \n",
      "Number of data sampels: 970009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop data sample with history length that is less than 5.\n",
    "\n",
    "df_data[\"history ID\"] = history_column[\"ID\"]\n",
    "df_data[\"history rating\"] = history_column[\"rating\"]\n",
    "\n",
    "df_data = df_data[df_data[\"history ID\"].apply(lambda x: len(x)) >= 5].reset_index(drop=True)\n",
    "\n",
    "history_column[\"ID\"] = [x for x in history_column[\"ID\"] if len(x) >= 5]\n",
    "history_column[\"rating\"] = [x for x in history_column[\"rating\"] if len(x) >= 5]\n",
    "history_column[\"hist length\"] = [len(x) for x in history_column[\"rating\"]]\n",
    "\n",
    "for idx, row in tqdm(df_data.iterrows()):\n",
    "    assert row[\"history ID\"] == history_column[\"ID\"][idx]\n",
    "    assert row[\"history rating\"] == history_column[\"rating\"][idx]\n",
    "    assert len(row[\"history rating\"]) == history_column[\"hist length\"][idx]\n",
    "\n",
    "\n",
    "print(df_data.head())\n",
    "\n",
    "print(f\"Number of data sampels: {len(df_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split & save user history sequence\n",
    "\n",
    "train_num = int(0.8 * len(df_data))\n",
    "valid_num = int(0.1 * len(df_data))\n",
    "test_num = len(df_data) - train_num - valid_num\n",
    "\n",
    "user_seq = {\n",
    "    \"history ID\": {\n",
    "        \"train\": history_column[\"ID\"][:train_num],\n",
    "        \"valid\": history_column[\"ID\"][train_num:train_num + valid_num],\n",
    "        \"test\": history_column[\"ID\"][train_num + valid_num:],\n",
    "    },\n",
    "    \"history rating\": {\n",
    "        \"train\": history_column[\"rating\"][:train_num],\n",
    "        \"valid\": history_column[\"rating\"][train_num:train_num + valid_num],\n",
    "        \"test\": history_column[\"rating\"][train_num + valid_num:],\n",
    "    },\n",
    "    \"history length\": {\n",
    "        \"train\": history_column[\"hist length\"][:train_num],\n",
    "        \"valid\": history_column[\"hist length\"][train_num:train_num + valid_num],\n",
    "        \"test\": history_column[\"hist length\"][train_num + valid_num:],\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train num: 776007\n",
      "Valid num: 97000\n",
      "Test num: 97002\n"
     ]
    }
   ],
   "source": [
    "# Save train/valid/test in parquet format\n",
    "\n",
    "df_train = df_data[:train_num].reset_index(drop=True)\n",
    "df_valid = df_data[train_num:train_num + valid_num].reset_index(drop=True)\n",
    "df_test = df_data[train_num + valid_num:].reset_index(drop=True)\n",
    "\n",
    "assert len(df_train) == train_num\n",
    "assert len(df_valid) == valid_num\n",
    "assert len(df_test) == test_num\n",
    "\n",
    "print(f\"Train num: {len(df_train)}\")\n",
    "print(f\"Valid num: {len(df_valid)}\")\n",
    "print(f\"Test num: {len(df_test)}\")\n",
    "\n",
    "df_train.to_parquet(os.path.join(target_dir, \"train.parquet.gz\"), compression=\"gzip\")\n",
    "df_valid.to_parquet(os.path.join(target_dir, \"valid.parquet.gz\"), compression=\"gzip\")\n",
    "df_test.to_parquet(os.path.join(target_dir, \"test.parquet.gz\"), compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-read for sanity check\n",
    "\n",
    "train_dataset = pd.read_parquet(os.path.join(target_dir, \"train.parquet.gz\"))\n",
    "valid_dataset = pd.read_parquet(os.path.join(target_dir, \"valid.parquet.gz\"))\n",
    "test_dataset = pd.read_parquet(os.path.join(target_dir, \"test.parquet.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the meta data for CTR\n",
    "\n",
    "meta_data = {\n",
    "    \"field_names\": field_names,\n",
    "    \"feature_count\": feature_count,\n",
    "    \"feature_dict\": feature_dict,\n",
    "    \"feature_offset\": feature_offset,\n",
    "    \"movie_id_to_title\": movie_id_to_title,\n",
    "    \"num_ratings\": 5,\n",
    "}\n",
    "\n",
    "\n",
    "json.dump(meta_data, open(os.path.join(target_dir, \"ctr-meta.json\"), \"w\"), ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "970009it [02:18, 7023.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ctr_X (970009, 8)\n",
      "ctr_Y (970009,)\n"
     ]
    }
   ],
   "source": [
    "# Convert df_data to CTR data via feature_dict\n",
    "\n",
    "ctr_X, ctr_Y = [], []\n",
    "for idx, row in tqdm(df_data.iterrows()):\n",
    "    ctr_X.append([feature_dict[field][row[field]] for field in field_names])\n",
    "    ctr_Y.append(int(row[\"labels\"]))\n",
    "\n",
    "ctr_X = np.array(ctr_X)\n",
    "ctr_Y = np.array(ctr_Y)\n",
    "print(\"ctr_X\", ctr_X.shape)\n",
    "print(\"ctr_Y\", ctr_Y.shape)\n",
    "feature_count_np = np.array(feature_count).reshape(1, -1)\n",
    "assert (ctr_X - feature_count_np <= 0).sum() == ctr_X.shape[0] * ctr_X.shape[1]\n",
    "assert (ctr_Y == 0).sum() + (ctr_Y == 1).sum() == ctr_Y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history ID train\n",
      "history ID valid\n",
      "history ID test\n",
      "history rating train\n",
      "history rating valid\n",
      "history rating test\n"
     ]
    }
   ],
   "source": [
    "# Truncate the user sequence up to 30, i.e., 5 <= length <= 30.\n",
    "\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "user_seq_trunc = {\n",
    "    \"history ID\": {}, \n",
    "    \"history rating\": {}, \n",
    "    \"history mask\": {}, \n",
    "}\n",
    "\n",
    "for hist_name in user_seq:\n",
    "    for split in user_seq[hist_name]:\n",
    "        if hist_name != \"history length\":\n",
    "            user_seq_trunc[hist_name][split] = pad_sequence(\n",
    "                [torch.tensor(x[-30:]) for x in user_seq[hist_name][split]], \n",
    "                batch_first=True, \n",
    "            )\n",
    "        else:\n",
    "            user_seq_trunc[\"history mask\"][split] = pad_sequence(\n",
    "                [torch.ones(min(x, 30)) for x in user_seq[hist_name][split]], \n",
    "                batch_first=True, \n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: (776007, 8)\n",
      "valid data: (97000, 8)\n",
      "test data: (97002, 8)\n",
      "train label: (776007,)\n",
      "valid label: (97000,)\n",
      "test label: (97002,)\n"
     ]
    }
   ],
   "source": [
    "# Save CTR data & truncated user sequence into one .h5 file\n",
    "\n",
    "with h5py.File(os.path.join(target_dir, f\"ctr.h5\"), \"w\") as hf:\n",
    "    hf.create_dataset(\"train data\", data=ctr_X[:train_num, :])\n",
    "    hf.create_dataset(\"valid data\", data=ctr_X[train_num:train_num + valid_num, :])\n",
    "    hf.create_dataset(\"test data\", data=ctr_X[train_num + valid_num:, :])\n",
    "    hf.create_dataset(\"train label\", data=ctr_Y[:train_num])\n",
    "    hf.create_dataset(\"valid label\", data=ctr_Y[train_num:train_num + valid_num])\n",
    "    hf.create_dataset(\"test label\", data=ctr_Y[train_num + valid_num:])\n",
    "    for hist_name in user_seq_trunc:\n",
    "        for split in user_seq_trunc[hist_name]:\n",
    "            hf.create_dataset(f\"{split} {hist_name}\", data=user_seq_trunc[hist_name][split])\n",
    "\n",
    "with h5py.File(os.path.join(target_dir, f\"ctr.h5\"), \"r\") as hf:\n",
    "    assert (ctr_X - np.concatenate([hf[\"train data\"][:], hf[\"valid data\"][:], hf[\"test data\"][:]], axis=0)).sum() == 0\n",
    "    assert (ctr_Y - np.concatenate([hf[\"train label\"][:], hf[\"valid label\"][:], hf[\"test label\"][:]], axis=0)).sum() == 0\n",
    "    for hist_name in user_seq_trunc:\n",
    "        for split in user_seq_trunc[hist_name]:\n",
    "            assert (user_seq_trunc[hist_name][split] - hf[f\"{split} {hist_name}\"][:]).sum() == 0\n",
    "\n",
    "    x = hf[\"train data\"][:]\n",
    "    assert (x - ctr_X[:train_num, :]).sum() == 0\n",
    "    print(f\"train data: {x.shape}\")\n",
    "    \n",
    "    x = hf[\"valid data\"][:]\n",
    "    assert (x - ctr_X[train_num:train_num + valid_num, :]).sum() == 0\n",
    "    print(f\"valid data: {x.shape}\")\n",
    "    \n",
    "    x = hf[\"test data\"][:]\n",
    "    assert (x - ctr_X[train_num + valid_num:, :]).sum() == 0\n",
    "    print(f\"test data: {x.shape}\")\n",
    "    \n",
    "    x = hf[\"train label\"][:]\n",
    "    assert (x - ctr_Y[:train_num]).sum() == 0\n",
    "    print(f\"train label: {x.shape}\")\n",
    "    \n",
    "    x = hf[\"valid label\"][:]\n",
    "    assert (x - ctr_Y[train_num:train_num + valid_num]).sum() == 0\n",
    "    print(f\"valid label: {x.shape}\")\n",
    "    \n",
    "    x = hf[\"test label\"][:]\n",
    "    assert (x - ctr_Y[train_num + valid_num:]).sum() == 0\n",
    "    print(f\"test label: {x.shape}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
